---
title: "Cleaning template - COVID-19 Behind Bars Historical Data Cleaning"
author: "Hope Johnson"
date: "10/26/2020"
output: html_document
---

```{r package setup, include=FALSE}
##Define package list
Packages<-c("tidyverse", "glue", "assertthat", "stringr", "lubridate", "devtools")
.packages = Packages
##Install CRAN packages (if not already installed)
.inst <- .packages %in% installed.packages()
if(length(.packages[!.inst]) > 0) install.packages(.packages[!.inst])
##Load packages into session 
lapply(.packages, require, character.only=TRUE)
devtools::install_github("uclalawcovid19behindbars/behindbarstools")
```

## Intro & Credits

This script is used to clean one state in the historical data concerning COVID-19 in state and federal prisons. Contributors to the historical data cleaning efforts include Hope Johnson, Michael Everett, Neal Marquez, Chase Hommeyer, Grace DiLaura, and Kalind Parish. Contributors to larger project include Sharon Dolovich, Aaron Littman, Danielle Flores, Poornima Rajeshwar, Victoria Rossi, and many others. 


## Load inputs

Input files: 

* Utilities script
* Historical data
* Date range to clean 
* Facility name look-up table 

```{r load inputs, echo=FALSE}
base_path <- file.path("~", "UCLA", "code", "historical", "historical-data")
data_path <- file.path(base_path, "data", "inputs")
##Load utilities function
util_path <- file.path(base_path, "R", "0-utilities.R")
source(util_path, local = knitr::knit_global())
##Facility name look-up table
f <- read_csv("https://raw.githubusercontent.com/uclalawcovid19behindbars/facility_data/master/data_sheets/fac_spellings.csv")
##Load population data
pop <- read_csv(file.path(data_path, "Prison_Boundaries.csv"))
```


```{r load data}
# no filter
df <- load_data(data_path, 
                "101820")
                # filter_state = "Florida") 
df_typed <- type_convert(df) 
df_out <- df_typed %>%
  select(!starts_with("...")) %>%
  select(!starts_with("lots")) %>%
  select(!starts_with("Bad")) %>%
  select(!c("V2", "V4", "V5", "V7", "V8", "V10")) %>%
  select(!c("Facility.", "Coder", "Housing.Type")) %>%
  select_if(~sum(!is.na(.)) > 0) %>% # rm 100% missing cols 
  

# FEDERAL
# If 'State.1' exists:
# - Make "Facility" = "Federal Prison"
# - Make "State" = {LOOKUP 'state.1' acronym --> full state name}

# OHIO
# If 'Residents.Quarantined' exists:
# - Force it as numeric
# - Put entries into 'Residents.Quarantine'

# TEXAS
# If 'Allred' exists:
# - investigate that date. facility name?

df_out %<>% 
  mutate(Staff.Deaths = coalesce_with_warnings(Staff.Deaths, Staff.Death)) %>%
  mutate(Resident.Deaths = coalesce_with_warnings(Resident.Deaths, Resident.Death)) %>%
  mutate(Residents.Confirmed = na_if(Residents.Confirmed, "n/a")) %>%
  mutate(Residents.Confirmed = as.numeric(Residents.Confirmed))

```

Columns that mean the same thing but have slightly different names: 
- Staff.Death, Staff.Deaths
- Staff.Recovered, Staff.Recoveries
- Staff.Quarantined, Staff.Quarantine
- Residents.Recovered, Residents.Recoveries
- Resident.Death, Residents.Deaths, Resident.Deaths..Confirmed., {? Resident.Deaths..Presumed.}
- Resident.Tested, Residents.Tested
- Inmates.Positive, Residents.Positive

```{r filter federal prisons}
df_out <- df_out %>%
  filter(Facility != "Federal Prison") %>%
  filter(Facility != "Federal RRC") 
```

```{r create date var}
df_out <- df_out %>%
  mutate(date = as_date(sheet_name, format = "%Om.%d.%y"))
```

```{r standardize facility names}
id_xwalk <- f %>%
  select(Count.ID, State, facility_name_raw, facility_name_clean) %>%
  unique() %>%
  mutate(facility_name_raw_merging = toupper(facility_name_raw))

# test <- df_out %>%
#   mutate(name_merging = behindbarstools::clean_fac_col_txt(Name, to_upper = TRUE))


df_out <- df_out %>%
  mutate(name_merging = toupper(Name)) %>%
  mutate(name_merging = str_remove_all(name_merging,"( |)- OPERATED BY THE")) %>%
  mutate(name_merging = str_remove_all(name_merging,"( |)- OPERATED BY")) %>%
  mutate(name_merging = str_remove_all(name_merging, "\\."))

df_mid <- nest_join(df_out, id_xwalk, 
                   by = c("name_merging" = "facility_name_raw_merging", 
                          "State" = "State")) %>% 
  hoist(id_xwalk, facility_name_clean = pluck("facility_name_clean", 1)) %>%
  mutate(facility_name_clean = map(facility_name_clean, first),
         facility_name_clean = as.character(facility_name_clean))

```


```{r facility merge checks, include = FALSE}
# show instances where merge didn't identify a clean name
ck <- anti_join(df_out, id_xwalk, 
                by = c("name_merging" = "facility_name_raw_merging", 
                          "State" = "State"))
print(ck)
```

```{r concat duplicate date/facilities}
n_distinct(df_out)
nrow(df_mid)
nrow(distinct(df_mid, sheet_name, facility_name_clean))
see_if(nrow(df_mid) == nrow(distinct(df_mid, sheet_name, facility_name_clean)))

df_mid %<>% 
  group_by(facility_name_clean, sheet_name) %>%
  mutate(dupe_fac_date = n() > 1) %>%
  ungroup() %>%
  relocate(dupe_fac_date, .before =) %>%
  mutate(fac_date = glue::glue('{facility_name_clean}_{sheet_name}')) %>%
  select(-id_xwalk)

df_comb <- df_mid %>%
  group_by(fac_date) %>%
  summarise_all(coalesce_by_column) %>%
  ungroup()

assert_that(nrow(df_comb) == nrow(distinct(df_comb, sheet_name, facility_name_clean)))
```

```{r plot cases/deaths}
df_comb <- flag_noncumulative_cases(df_comb)
df_comb <- flag_noncumulative_deaths(df_comb)

# lag cases overall 
df_comb %>%
  filter(facility_name_clean != "STATEWIDE") %>%
  ggplot(data = ., 
         aes(x = date, y = lag_change_cases, group = facility_name_clean)) +
    geom_line(alpha=0.6 , size=.5, color = "black") +
    scale_x_date(date_labels = "%m") + 
    labs(x = "Date",
      y = "lag_change_cases")

# lag deaths overall
df_comb %>%
  filter(facility_name_clean != "STATEWIDE") %>%
  ggplot(data = ., 
         aes(x = date, y = lag_change_deaths, group = facility_name_clean)) +
    geom_line(alpha=0.6 , size=.5, color = "black") +
    scale_x_date(date_labels = "%m") + 
    labs(x = "Date",
      y = "lag_change_deaths")

# plot lag counts by facility
lag_case_plots <- plot_lags(df_comb, "date", "lag_change_cases")
```


```{r plot death data}
df_comb <- flag_noncumulative_deaths(df_comb)

df_comb %>%
  filter(facility_name_clean != "STATEWIDE") %>%
  ggplot(data = ., 
         aes(x = date, y = lag_change_deaths, group = facility_name_clean)) +
    geom_line(alpha=0.6 , size=.5, color = "black") +
    scale_x_date(date_labels = "%m") + 
    labs(x = "Date",
      y = "lag_change_deaths")

lag_death_plots <- plot_lags(df_comb, "date", "lag_change_deaths")
```

Find date spans / week spans with no data. Instances where the count went down by one, it could be a PDF was misread. 

```{r}
dates <- df_comb %>%
  arrange(date) %>%
  count(date)
dates

ggplot(data = dates, 
       aes(x = date, y = n)) +
  geom_bar(stat="identity") +
  labs(x = "Date",
    y = "n instances")
```

Merge in population data.

```{r population data merge}
# clean population data

```