---
title: "Clean Florida - COVID-19 Behind Bars Historical Data Cleaning"
author: "Hope Johnson"
date: "10/26/2020"
output: html_document
---

```{r package setup, include=FALSE}
##Define package list
Packages<-c("tidyverse", "glue", "assertthat", "stringr", "lubridate")
.packages = Packages
##Install CRAN packages (if not already installed)
.inst <- .packages %in% installed.packages()
if(length(.packages[!.inst]) > 0) install.packages(.packages[!.inst])
##Load packages into session 
lapply(.packages, require, character.only=TRUE)
```

## Intro & Credits

This script is used to clean one state in the historical data concerning COVID-19 in state and federal prisons. Contributors to the historical data cleaning efforts include Hope Johnson, Michael Everett, Neal Marquez, Chase Hommeyer, Grace DiLaura, and Kalind Parish. Contributors to larger project include Sharon Dolovich, Aaron Littman, Danielle Flores, Poornima Rajeshwar, Victoria Rossi, and many others. 


## Load inputs

Input files: 

* Utilities script
* Historical data
* Date range to clean 
* Facility name look-up table 

```{r load inputs, echo=FALSE}
base_path <- file.path("~", "UCLA", "code", "historical", "historical-data")
data_path <- file.path(base_path, "data", "inputs")
##Load utilities function
util_path <- file.path(base_path, "R", "0-utilities.R")
source(util_path, local = knitr::knit_global())
##Facility name look-up table
f <- read_csv("https://raw.githubusercontent.com/uclalawcovid19behindbars/facility_data/master/data_sheets/fac_spellings.csv")
##Load population data
pop <- read_csv(file.path(data_path, "Prison_Boundaries.csv"))
```


```{r load data, message=FALSE}
df <- load_data(data_path, 
                "103020",
                filter_state = "Florida") 
df_typed <- type_convert(df)
```

Fill in missing values of `Staff.Deaths` with non-missing values of `Staff.Death`, when those exist. Do the same with `Resident.Death`/`Resident.Deaths`.

```{r combine similar columns}
df_out <- df_typed %>%
  select(!starts_with("...")) %>%
  select(!starts_with("lots")) %>%
  select(!starts_with("Bad")) %>%
  select(!c("V2", "V4", "V5", "V7", "V8", "V10")) %>%
  select(!c("Facility.", "Coder", "Housing.Type")) %>%
  select_if(~sum(!is.na(.)) > 0) # rm 100% missing cols 

# test <- df_out %>%
#   filter((!is.na(Staff.Death)) & (!is.na(Staff.Deaths))) %>%
#   mutate(check_equal = ifelse(Staff.Death == Staff.Deaths, TRUE, FALSE)) %>%
#   select(Staff.Death, Staff.Deaths, check_equal, Facility, sheet_name)

# re-write coalesce that gives a warning when there are duplicate values (especially if not equal)
df_out %<>% 
  mutate(Staff.Deaths = coalesce_with_warnings(Staff.Deaths, Staff.Death)) %>%
  mutate(Resident.Deaths = coalesce_with_warnings(Resident.Deaths, Resident.Death)) %>%
  mutate(Residents.Confirmed = na_if(Residents.Confirmed, "n/a")) %>%
  mutate(Residents.Confirmed = as.numeric(Residents.Confirmed))
```


```{r filter federal prisons}
# Q
# Filter out administrative, community corrections, county jail?
df_out <- df_out %>%
  filter(Facility != "Federal Prison") %>%
  filter(Facility != "Federal RRC") 
```

```{r create date var}
df_out <- df_out %>%
  mutate(date = as_date(sheet_name, format = "%Om.%d.%y"))
```


```{r standardize facility names}
id_xwalk <- f %>%
  select(Count.ID, State, facility_name_raw, facility_name_clean) %>%
  unique() %>%
  mutate(facility_name_raw_merging = tolower(facility_name_raw))

df_out %<>%
  mutate(name_merging = tolower(Name)) %>%
  mutate(name_merging = str_remove_all(name_merging,"( |)- operated by the")) %>%
  mutate(name_merging = str_remove_all(name_merging,"( |)- operated by")) %>%
  mutate(name_merging = str_remove_all(name_merging, "\\."))

df_mid <- nest_join(df_out, id_xwalk, 
                   by = c("name_merging" = "facility_name_raw_merging", 
                          "State" = "State")) %>%
        hoist(id_xwalk,
              facility_name_clean = pluck("facility_name_clean", 1)) %>%
  mutate(facility_name_clean = map(facility_name_clean, first),
         facility_name_clean = as.character(facility_name_clean))
```

```{r facility merge checks, include = FALSE}
# show instances where merge didn't identify a clean name
ck <- anti_join(df_out, id_xwalk, 
                by = c("name_merging" = "facility_name_raw_merging", 
                          "State" = "State"))
View(ck)

# Any other "GEO groups" reported in FL?
# No
df_mid %>%
  filter(str_detect(Name, regex('geo', ignore_case = TRUE)) )

# Ask: was there black water or south bay geo group on these dates? 
# Answer: Yes

another_check <- df_mid %>%
  filter(str_detect(Name, regex('south bay', ignore_case = TRUE)) | str_detect(Name, regex('black', ignore_case = TRUE))) %>%
  filter(date >= as.Date("2020-07-08") & date <= as.Date("2020-07-11"))
```

Figure out duplicate date/facilities, concatenate those instances from multiple rows into one. This most often occurs because we scraped death data and infections data from separate tables.

```{r concat duplicate date/facilities}
n_distinct(df_out)
nrow(df_mid)
nrow(distinct(df_mid, sheet_name, facility_name_clean))
see_if(nrow(df_mid) == nrow(distinct(df_mid, sheet_name, facility_name_clean)))

df_mid %<>% 
  group_by(facility_name_clean, sheet_name) %>%
  mutate(dupe_fac_date = n() > 1) %>%
  ungroup() %>%
  relocate(dupe_fac_date, .before =) %>%
  mutate(fac_date = glue::glue('{facility_name_clean}_{sheet_name}')) %>%
  select(-id_xwalk)

df_comb <- df_mid %>%
  group_by(fac_date) %>%
  summarise_all(coalesce_by_column) %>%
  ungroup()

assert_that(nrow(df_comb) == nrow(df_mid)) # make sure we didn't pick up any extra rows
assert_that(nrow(df_comb) == nrow(distinct(df_comb, sheet_name, facility_name_clean)))
```

Find non-cumulative counts, separate those into "active" and "confirmed". Confirmed = active + recovered + deaths.

```{r}
df_comb <- flag_noncumulative_cases(df_comb)
df_comb <- flag_noncumulative_deaths(df_comb)

# lag cases 
df_comb %>%
  filter(facility_name_clean != "STATEWIDE") %>%
  ggplot(data = ., 
         aes(x = date, y = lag_change_cases, group = facility_name_clean)) +
    geom_line(alpha=0.6 , size=.5, color = "black") +
    scale_x_date(date_labels = "%m") + 
    labs(x = "Date",
      y = "lag_change_cases")

# lag deaths
df_comb %>%
  filter(facility_name_clean != "STATEWIDE") %>%
  ggplot(data = ., 
         aes(x = date, y = lag_change_deaths, group = facility_name_clean)) +
    geom_line(alpha=0.6 , size=.5, color = "black") +
    scale_x_date(date_labels = "%m") + 
    labs(x = "Date",
      y = "lag_change_deaths")

# df_comb %>%
#   filter(facility_name_clean != "STATEWIDE") %>%
#   ggplot(data = ., 
#          aes(x = date, y = Resident.Deaths, group = facility_name_clean)) +
#     geom_area(alpha=0.6 , size=.5, color = "white") +
#     scale_x_date(date_labels = "%m") 


# # TO DO: create lag death chart 
# # Aggregate to weekly, bi-weekly
death_check <- df_comb %>%
  group_by(date) %>%
  summarise(total_deaths = sum(Resident.Deaths)) 


# plot lag counts by facility
lag_case_plots <- plot_lag_cases(df_comb)
lag_death_plots <- plot_lag_deaths(df_comb)

# ST LUCE COUNTY JAIL
# Active --> cumulative 
df_comb <- df_comb %>% 
  group_by(facility_name_clean) %>% 
  arrange(date) %>%
  mutate(temp_cumulative_var = cumsum(Residents.Confirmed)) %>%
  ungroup %>%
  mutate(Residents.Confirmed = ifelse(facility_name_clean == "ST LUCE COUNTY JAIL",
                       temp_cumulative_var, Residents.Confirmed)) %>%
  select(-temp_cumulative_var)

# test <- create_cumulative_count(df_comb, "ST LUCE COUNTY JAIL", 
#                                 "Residents.Confirmed")


# noncumulative <- df_comb %>%
#   filter(cumulative == FALSE) %>%
#   select(facility_name_raw, facility_name_clean, date, 
#          Residents.Confirmed, previous_date_value, lag_change, cumulative, 
#          Residents.Recovered)
  

# Come back to SFRC (south florida reception center?)
# Strange thing with +71 one day, -71 four days later
# TO DO: GO LOOK FOR PERMA-CC on this day for perma-CC

# write a function for large negatives/positives followed by large positives/negatives

df_comb %>% 
  filter(facility_name_clean == "SFRC") %>% 
  ggplot(., aes(x=date, y=lag_change)) +
    geom_point() +
    xlab("") +
    scale_x_date(date_labels = "%b") + 
    ggtitle(unique("SFRC"))


df_comb %>% 
  filter(facility_name_clean == "SFRC") %>% 
  ggplot(., aes(x=date, y=Residents.Confirmed)) +
    geom_point() +
    xlab("") +
    scale_x_date(date_labels = "%b") + 
    ggtitle(unique("SFRC"))
```


Find date spans / week spans with no data. Instances where the count went down by one, it could be a PDF was mis-read. Might want to go back to the perma-CC and resolve these instances. 

```{r}
dates <- df_comb %>%
  arrange(date) %>%
  count(date)
dates

ggplot(data = dates, 
       aes(x = date, y = n)) +
  geom_bar(stat="identity") +
  labs(x = "Date",
    y = "n instances")

# 2020-10-01: Only 1 facility counted (county jail)
# Not worried about this
```


Merge in population data.

```{r population data merge}
# clean HIFLD population data
pop_merging <- pop %>%
  filter(STATE == "FL") %>%
  select(NAME, FACILITYID, POPULATION) %>%
  mutate(State = "Florida") %>%
  mutate(POPULATION = ifelse(POPULATION < 0, NA, POPULATION)) %>%
  mutate(name_merging = tolower(NAME),
         name_merging = str_replace(name_merging, "correctional institution", "ci"),
         name_merging = str_replace(name_merging, "correctional facility", "cf"),
         name_merging = str_remove_all(name_merging, ", east unit"),
         name_merging = str_remove_all(name_merging, ", west unit"),
         name_merging = str_remove_all(name_merging, "\\.")) %>%
  group_by(name_merging) %>%
  mutate(POPULATION = sum(POPULATION, na.rm = TRUE)) %>%
  distinct(name_merging, .keep_all = TRUE)

# Unresolved pop data: 
# BLACKWATER 
# Central office
# Community corrections region 1-4

see_if(nrow(pop_merging) == n_distinct(pop_merging$name_merging))

# merge HIFLD data to facility name crosswalk
pop_joined <-left_join(pop_merging, id_xwalk, 
                   by = c("name_merging" = "facility_name_raw_merging", 
                          "State" = "State")) %>%
  drop_na(facility_name_clean)

# merge HIFLD population data to data 
test_join <- semi_join(df_comb, pop_joined, by = "facility_name_clean")
dim(test_join)
dim(df_comb)


dist_fac <- tibble(name = unique(df_comb$facility_name_clean))
dist_merged <- tibble(name = unique(pop_joined$facility_name_clean))
# check facilities that aren't overlapping
ck <- anti_join(dist_fac, dist_merged)

```



