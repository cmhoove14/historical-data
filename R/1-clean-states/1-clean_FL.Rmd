---
title: "Clean Florida - COVID-19 Behind Bars Historical Data Cleaning"
author: "Hope Johnson"
date: "10/26/2020"
output: html_document
---

```{r package setup, include=FALSE}
##Define package list
Packages<-c("tidyverse", "glue", "assertthat", "stringr", "lubridate", "devtools")
.packages = Packages
##Install CRAN packages (if not already installed)
.inst <- .packages %in% installed.packages()
if(length(.packages[!.inst]) > 0) install.packages(.packages[!.inst])
##Load packages into session 
lapply(.packages, require, character.only=TRUE)
devtools::install_github("uclalawcovid19behindbars/behindbarstools")
```

## Intro & Credits

This script is used to clean one state in the historical data concerning COVID-19 in state and federal prisons. Contributors to the historical data cleaning efforts include Hope Johnson, Michael Everett, Neal Marquez, Chase Hommeyer, Grace DiLaura, and Kalind Parish. Contributors to larger project include Sharon Dolovich, Aaron Littman, Danielle Flores, Poornima Rajeshwar, Victoria Rossi, and many others. 


## Load inputs

Input files: 

* Utilities script
* Historical data
* Date range to clean 
* Facility name look-up table 

```{r load inputs, echo=FALSE}
base_path <- file.path("~", "UCLA", "code", "historical", "historical-data")
data_path <- file.path(base_path, "data", "inputs")
##Load utilities function
util_path <- file.path(base_path, "R", "0-utilities.R")
source(util_path, local = knitr::knit_global())
##Facility name look-up table
f <- read_csv("https://raw.githubusercontent.com/uclalawcovid19behindbars/facility_data/master/data_sheets/fac_spellings.csv")
##Load population data
pop <- read_csv(file.path(data_path, "Prison_Boundaries.csv"))
```


```{r load data, message=FALSE}
df <- load_data(data_path, 
                "11420",
                filter_state = "Florida") 
df_typed <- type_convert(df)
```

Fill in missing values of `Staff.Deaths` with non-missing values of `Staff.Death`, when those exist. Do the same with `Resident.Death`/`Resident.Deaths`.

```{r combine similar columns}
df_out <- df_typed %>%
  select(!starts_with("...")) %>%
  select(!starts_with("lots")) %>%
  select(!starts_with("Bad")) %>%
  select(!c("V2", "V4", "V5", "V7", "V8", "V10")) %>%
  select(!c("Facility.", "Coder", "Housing.Type")) %>%
  select_if(~sum(!is.na(.)) > 0) # rm 100% missing cols 

df_out %<>% 
  mutate(Staff.Deaths = coalesce_with_warnings(Staff.Deaths, Staff.Death)) %>%
  mutate(Resident.Deaths = coalesce_with_warnings(Resident.Deaths, Resident.Death)) %>%
  mutate(Residents.Confirmed = na_if(Residents.Confirmed, "n/a")) %>%
  mutate(Residents.Confirmed = as.numeric(Residents.Confirmed))
```


```{r filter federal prisons}
df_out <- df_out %>%
  filter(Facility != "Federal Prison") %>%
  filter(Facility != "Federal RRC") 
```

```{r create date var}
df_out <- df_out %>%
  mutate(date = as_date(sheet_name, format = "%Om.%d.%y"))
```


```{r standardize facility names}
id_xwalk <- f %>%
  select(Count.ID, State, facility_name_raw, facility_name_clean) %>%
  unique() %>%
  mutate(facility_name_raw_merging = toupper(facility_name_raw))

# test <- df_out %>%
#   mutate(name_merging = behindbarstools::clean_fac_col_txt(Name, to_upper = TRUE))
# 

df_out <- df_out %>%
  mutate(name_merging = toupper(Name)) %>%
  mutate(name_merging = str_remove_all(name_merging,"( |)- OPERATED BY THE")) %>%
  mutate(name_merging = str_remove_all(name_merging,"( |)- OPERATED BY")) %>%
  mutate(name_merging = str_remove_all(name_merging, "\\."))

df_mid <- nest_join(df_out, id_xwalk, 
                   by = c("name_merging" = "facility_name_raw_merging", 
                          "State" = "State")) %>% 
  hoist(id_xwalk, facility_name_clean = pluck("facility_name_clean", 1)) %>%
  mutate(facility_name_clean = map(facility_name_clean, first),
         facility_name_clean = as.character(facility_name_clean))
```

```{r facility merge checks, include = FALSE}
# show instances where merge didn't identify a clean name
ck <- anti_join(df_out, id_xwalk, 
                by = c("name_merging" = "facility_name_raw_merging", 
                          "State" = "State"))
print(ck)
# Any other "GEO groups" reported in FL?
# No
df_mid %>%
  filter(str_detect(Name, regex('geo', ignore_case = TRUE)) )

# Ask: was there black water or south bay geo group on these dates? 
# Answer: Yes
another_check <- df_mid %>%
  filter(str_detect(Name, regex('south bay', ignore_case = TRUE)) | str_detect(Name, regex('black', ignore_case = TRUE))) %>%
  filter(date >= as.Date("2020-07-08") & date <= as.Date("2020-07-11"))
```

Remove "GEO Group" observations for July 8, 10, and 11. These observations were an OCR error because the facilities on those dates had names that spanned multiple lines. If we included these observations, we would be double-counting deaths in South Bay GEO Group prison. 

```{r drop geo-group observations}
df_mid <- df_mid %>%
  filter(!(Name == "GEO Group Inc" & (date >= as.Date("2020-07-08") & date <= as.Date("2020-07-11"))))
```

Figure out duplicate date/facilities, concatenate those instances from multiple rows into one. This most often occurs because we scraped death data and infections data from separate tables.

```{r concat duplicate date/facilities}
n_distinct(df_out)
nrow(df_mid)
nrow(distinct(df_mid, sheet_name, facility_name_clean))
see_if(nrow(df_mid) == nrow(distinct(df_mid, sheet_name, facility_name_clean)))

df_mid %<>% 
  group_by(facility_name_clean, sheet_name) %>%
  mutate(dupe_fac_date = n() > 1) %>%
  ungroup() %>%
  relocate(dupe_fac_date, .before =) %>%
  mutate(fac_date = glue::glue('{facility_name_clean}_{sheet_name}')) %>%
  select(-id_xwalk)

df_comb <- df_mid %>%
  group_by(fac_date) %>%
  summarise_all(coalesce_by_column) %>%
  ungroup()

# Fix coalesce instance where it selected 0 rather than 1
df_comb$Staff.Confirmed[df_comb$fac_date == "LAKE CITY CF_4.17.20"] <- 1

assert_that(nrow(df_comb) == nrow(distinct(df_comb, sheet_name, facility_name_clean)))
```

Find non-cumulative counts, separate those into "active" and "confirmed". Confirmed = active + recovered + deaths.

```{r plot cases/deaths}
df_comb <- flag_noncumulative_cases(df_comb)
df_comb <- flag_noncumulative_deaths(df_comb)

# lag cases overall 
df_comb %>%
  filter(facility_name_clean != "STATEWIDE") %>%
  ggplot(data = ., 
         aes(x = date, y = lag_change_cases, group = facility_name_clean)) +
    geom_line(alpha=0.6 , size=.5, color = "black") +
    scale_x_date(date_labels = "%m") + 
    labs(x = "Date",
      y = "lag_change_cases")

# lag deaths overall
df_comb %>%
  filter(facility_name_clean != "STATEWIDE") %>%
  ggplot(data = ., 
         aes(x = date, y = lag_change_deaths, group = facility_name_clean)) +
    geom_line(alpha=0.6 , size=.5, color = "black") +
    scale_x_date(date_labels = "%m") + 
    labs(x = "Date",
      y = "lag_change_deaths")

# plot lag counts by facility
lag_case_plots <- plot_lags(df_comb, "date", "lag_change_cases")
```

Investigate apparent non-cumulative counts at St. Luce County Jail. There was no death data reported for St. Luce, so we don't deal with any non-cumulative death counts for that facility.

```{r St luce verification}
df_comb %>% 
  filter(Name == "ST LUCE COUNTY JAIL") %>%
  select(date, Resident.Deaths, Resident.Death, lag_change_deaths, cumulative_deaths,
              Residents.Confirmed, lag_change_cases, cumulative_cases)

lag_case_plots %>% 
  filter(facility_name_clean == "ST LUCE COUNTY JAIL") %>% 
  pull(plots)

# ST LUCE COUNTY JAIL
# Active cases --> cumulative cases
df_comb <- df_comb %>% 
  group_by(facility_name_clean) %>% 
  arrange(date) %>%
  mutate(temp_cumulative_cases_var = cumsum(Residents.Confirmed)) %>%
  ungroup %>%
  mutate(Residents.Confirmed = ifelse(facility_name_clean == "ST LUCE COUNTY JAIL",
                       temp_cumulative_cases_var, Residents.Confirmed)) %>%
  select(-temp_cumulative_cases_var)
```

Starting on 10/28, we stopped getting facility-specific death counts. Instead, the state moved to reporting exclusively state-wide death counts (non facility-specific). Up until this point, the state-wide death counts were "STATE-WIDE FOR NON-SPECIFIC FACILITIES", in the range of 0-25. To calculate the state-wide death count up until 10/28, we add up this reported number with the sum of all deaths by facility.

Note that between 9/29 and 10/26, the facility-specific death counts stopped getting properly scraped. So although these values were being provided by the state, we do not capture the counts in these data. Therefore, both the facility-specific death counts and the state-wide death count for this date range are absolute minimums.

```{r clean death data}
# before 10/28, statewide = statewide + (minimum) sum of all facilities
# after 10/28, statewide = statewide

deaths_by_date <- df_comb %>%
  filter(facility_name_clean != "STATEWIDE") %>%
  group_by(date) %>%
  summarise(all_res_deaths = behindbarstools::sum_na_rm(Resident.Deaths))

df_sw <- left_join(df_comb, deaths_by_date, by = "date")

df_sw <- df_sw %>%
  mutate(Resident.Deaths = case_when(
    date < as.Date("2020-10-30") & facility_name_clean == "STATEWIDE" ~ behindbarstools::vector_sum_na_rm(Resident.Deaths, all_res_deaths),
    TRUE ~ Resident.Deaths)) 

# flag dates when the facility-specific death counts failed
# between 9/29 and 10/26 
df_sw$scraper_failed <- ifelse(((df_sw$date >= as.Date("2020-09-29") & 
                                   df_sw$date < as.Date("2020-10-28")) & 
                                  df_sw$facility_name_clean != "STATEWIDE"),
                               TRUE, FALSE)

df_sw <- df_sw %>%
  mutate(Resident.Deaths = ifelse(scraper_failed == TRUE,
                                  NA, Resident.Deaths))

df_sw %>%
  filter(facility_name_clean == "STATEWIDE" | facility_name_clean == "UNION CI") %>%
  select(facility_name_clean, date, Resident.Deaths, lag_change_deaths, all_res_deaths, scraper_failed) 
```

```{r plot cleaned death data}
df_sw <- flag_noncumulative_deaths(df_sw)
lag_death_plots <- plot_lags(df_sw, "date", "lag_change_deaths")

## save them 
# for (i in 1:nrow(lag_death_plots)){
#   facility_name <- lag_death_plots$facility_name_clean[[i]]
#   plot_name <- paste0(facility_name, ".png")
#   ggsave(paste0(plot_name, "_LagChangeDeaths.png"), lag_death_plots$plot[[i]],
#          path = file.path(base_path, "plots", "FL"))
# }

df_sw %>%
  filter(facility_name_clean != "STATEWIDE") %>%
  ggplot(data = ., 
         aes(x = date, y = lag_change_deaths, group = facility_name_clean)) +
    geom_line(alpha=0.6 , size=.5, color = "black") +
    scale_x_date(date_labels = "%m") + 
    labs(x = "Date",
      y = "lag_change_deaths")
```

Highlight places with large (absolute value) lag change in deaths, counts.

```{r abs lag change - deaths}
investigate <- df_sw %>%
  group_by(facility_name_clean) %>%
  summarise(sum_covid_cases = sum(abs(lag_change_cases), na.rm = TRUE),
            sum_covid_deaths = sum(abs(lag_change_deaths), na.rm = TRUE))
# write_csv(investigate, file.path(base_path, "data", "outputs", "FLCovidByFacility.csv"))

monthly_deaths <- df_sw %>%
  filter(facility_name_clean != "STATEWIDE") %>%
  group_by(month = month(date), year = year(date), facility_name_clean) %>%
  summarise(sum_covid_deaths = sum(lag_change_deaths, na.rm = TRUE)) %>%
  ungroup() %>%
  mutate(yr_month = glue('{year}_{month}'))
#write_csv(monthly_deaths, file.path(base_path, "data", "outputs", "FLCovidByFacilityMonth.csv"))


lag_death_plots %>% 
  filter(facility_name_clean == "RMC") %>% 
  pull(plot)

View(df_sw %>% filter(Name == "RMC") %>%
       select(date, Resident.Deaths, lag_change_deaths, cumulative_deaths))
```

Find date spans / week spans with no data. Instances where the count went down by one, it could be a PDF was misread. 

```{r}
dates <- df_sw %>%
  arrange(date) %>%
  count(date)
dates

ggplot(data = dates, 
       aes(x = date, y = n)) +
  geom_bar(stat="identity") +
  labs(x = "Date",
    y = "n instances")
```

Merge in population data.

```{r population data merge}
# clean HIFLD population data
pop_merging <- pop %>%
  filter(STATE == "FL") %>%
  select(NAME, FACILITYID, POPULATION) %>%
  mutate(State = "Florida") %>%
  mutate(POPULATION = ifelse(POPULATION < 0, NA, POPULATION)) %>%
  mutate(name_merging = tolower(NAME),
         name_merging = str_replace(name_merging, "correctional institution", "ci"),
         name_merging = str_replace(name_merging, "correctional facility", "cf"),
         name_merging = str_remove_all(name_merging, ", east unit"),
         name_merging = str_remove_all(name_merging, ", west unit"),
         name_merging = str_remove_all(name_merging, "\\.")) %>%
  group_by(name_merging) %>%
  mutate(POPULATION = sum(POPULATION, na.rm = TRUE)) %>%
  distinct(name_merging, .keep_all = TRUE)

# Unresolved pop data: 
# BLACKWATER 
# Central office
# Community corrections region 1-4

see_if(nrow(pop_merging) == n_distinct(pop_merging$name_merging))

# merge HIFLD data to facility name crosswalk
pop_joined <-left_join(pop_merging, id_xwalk, 
                   by = c("name_merging" = "facility_name_raw_merging", 
                          "State" = "State")) %>%
  drop_na(facility_name_clean)

# merge HIFLD population data to data 
test_join <- semi_join(df_comb, pop_joined, by = "facility_name_clean")
dim(test_join)
dim(df_comb)


dist_fac <- tibble(name = unique(df_comb$facility_name_clean))
dist_merged <- tibble(name = unique(pop_joined$facility_name_clean))
# check facilities that aren't overlapping
ck <- anti_join(dist_fac, dist_merged)
```